% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/fmin.R
\name{fmin}
\alias{fmin}
\title{Minimize a function f using a Quasi-Newton method}
\usage{
fmin(f, start, gfn = NULL, Hfn = NULL, maxit = 1000, tol = 1e-07,
  hessupdate = 10, maxhalfsteps = 10, verbose = FALSE, digits = 4,
  ...)
}
\arguments{
\item{f}{function to be minimised which takes parameter vector as first argument}

\item{start}{vector of starting values}

\item{gfn}{(optional) gradient function of f, uses finite differencing otherwise}

\item{Hfn}{(optional) hessian function of f, uses finite differencing otherwise}

\item{maxit}{maximum number of iterations to try}

\item{tol}{tolerance for stopping criteria}

\item{hessupdate}{number of iterations for which to update approximate BFGS Hessian with finite-difference Hessian. If set to zero, then always use finite-difference. If negative then never use it.}

\item{maxhalfsteps}{maximum number of halfsteps to take when ensuring gradient descent}

\item{verbose}{if TRUE, function value and then parameter value are printed for each iteration}

\item{digits}{number of digits to print when verbose = TRUE}

\item{...}{other named arguments to f}
}
\value{
a list with elements:
\itemize{
  \item estimate - a vector of the optimal estimates
  \item value -  value of the objective function at the optimum
  \item g - gradient vector at the optimum
  \item H - hessian at the optimum
  \item conv - is TRUE if convergence was satisfied, otherwise may not have converged on optimum
  \item niter: number of iterations taken
}
}
\description{
Algorithm uses initial Hessian equal to identity matrix and then updates it using BFGS formula: it updates by Cholesky factor. Every hessupdate iterations, the approximate BFGS Hessian is replaced by the finite-difference approximate. A cubic line search is used to determined step size. Step direction is by Newton's method. Stopping criteria are relative gradient and relative step length.
}
